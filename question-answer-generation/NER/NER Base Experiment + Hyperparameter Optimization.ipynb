{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agus/anaconda3/envs/basic/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/agus/anaconda3/envs/basic/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from stanford_postagger.stanford_wrapper import StanfordPOSTagger as StanfordPOSTaggerWrapper\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import scipy\n",
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/conll2003/train.txt', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "del lines[0]\n",
    "del lines[0]\n",
    "\n",
    "dataset = []\n",
    "sentence = []\n",
    "for line in lines:\n",
    "    splitter = line.strip().split(' ')\n",
    "    if splitter[0] == '':\n",
    "        continue\n",
    "    elif (splitter[0] == '-DOCSTART-'):\n",
    "        dataset.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        token = splitter[0]\n",
    "        tag = splitter[3]\n",
    "        sentence.append((token, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_conlltxt2dataset(filename):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    del lines[0]\n",
    "    del lines[0]\n",
    "    \n",
    "    dataset = []\n",
    "    sentence = []\n",
    "    for line in lines:\n",
    "        splitter = line.strip().split(' ')\n",
    "        if splitter[0] == '':\n",
    "            continue\n",
    "        elif (splitter[0] == '-DOCSTART-'):\n",
    "            dataset.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            token = splitter[0]\n",
    "            tag = splitter[3]\n",
    "            sentence.append((token, tag))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = convert_conlltxt2dataset('datasets/conll2003/train.txt')\n",
    "validation_dataset = convert_conlltxt2dataset('datasets/conll2003/valid.txt')\n",
    "test_dataset = convert_conlltxt2dataset('datasets/conll2003/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'B-ORG'),\n",
       " ('rejects', 'O'),\n",
       " ('German', 'B-MISC'),\n",
       " ('call', 'O'),\n",
       " ('to', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Postag to Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('+44', 'CD'), ('171', 'CD')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postagger = StanfordPOSTaggerWrapper()\n",
    "postag = postagger.tag('+44 171')\n",
    "postag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_postag2dataset(dataset):\n",
    "    postagger = StanfordPOSTaggerWrapper()\n",
    "    dataset_with_postag = []\n",
    "    for sent in dataset:\n",
    "        postagged_sent = []\n",
    "        for index, (token, tag) in enumerate(sent):\n",
    "            postagged_token = postagger.tag(token)\n",
    "            postagged_sent.append((token, postagged_token[0][1], tag))\n",
    "        dataset_with_postag.append(postagged_sent)\n",
    "        \n",
    "    return dataset_with_postag\n",
    "\n",
    "postagged_train_dataset = add_postag2dataset(train_dataset)\n",
    "postagged_validation_dataset = add_postag2dataset(validation_dataset)\n",
    "postagged_test_dataset = add_postag2dataset(test_dataset)\n",
    "\n",
    "# Delete Unused Dataset\n",
    "del train_dataset\n",
    "del validation_dataset\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP', 'B-ORG'),\n",
       " ('rejects', 'VBZ', 'O'),\n",
       " ('German', 'JJ', 'B-MISC'),\n",
       " ('call', 'NN', 'O'),\n",
       " ('to', 'TO', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postagged_train_dataset[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    # Ortographic Feature, Word, POSTag & N-Gram\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word[:2]': word[:2],\n",
    "        'word[:3]': word[:3],\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2]\n",
    "    }\n",
    "    \n",
    "    # Position\n",
    "    features.update({\n",
    "        'pos_front': i,\n",
    "        'pos_end': len(sent) - i\n",
    "    })\n",
    "    \n",
    "    # Bag Of Words\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2postag(sent):\n",
    "    return [postag for token, postag, label in sent]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'EU',\n",
       " 'word.lower()': 'eu',\n",
       " 'word[-3:]': 'EU',\n",
       " 'word[-2:]': 'EU',\n",
       " 'word[:2]': 'EU',\n",
       " 'word[:3]': 'EU',\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'word.isupper()': True,\n",
       " 'postag': 'NNP',\n",
       " 'postag[:2]': 'NN',\n",
       " 'pos_front': 0,\n",
       " 'pos_end': 469,\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'rejects',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'VBZ',\n",
       " '+1:postag[:2]': 'VB'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(postagged_train_dataset[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(sent) for sent in postagged_train_dataset]\n",
    "y_train = [sent2labels(sent) for sent in postagged_train_dataset]\n",
    "\n",
    "X_val = [sent2features(sent) for sent in postagged_validation_dataset]\n",
    "y_val = [sent2labels(sent) for sent in postagged_validation_dataset]\n",
    "\n",
    "X_test = [sent2features(sent) for sent in postagged_test_dataset]\n",
    "y_test = [sent2labels(sent) for sent in postagged_test_dataset]\n",
    "\n",
    "del postagged_train_dataset\n",
    "del postagged_validation_dataset\n",
    "del postagged_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'EU',\n",
       " 'word.lower()': 'eu',\n",
       " 'word[-3:]': 'EU',\n",
       " 'word[-2:]': 'EU',\n",
       " 'word[:2]': 'EU',\n",
       " 'word[:3]': 'EU',\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'word.isupper()': True,\n",
       " 'postag': 'NNP',\n",
       " 'postag[:2]': 'NN',\n",
       " 'pos_front': 0,\n",
       " 'pos_end': 469,\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'rejects',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'VBZ',\n",
       " '+1:postag[:2]': 'VB'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 538 ms, total: 31.5 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233657955716351"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.865     0.875     0.870      1658\n",
      "      I-LOC      0.776     0.745     0.760       255\n",
      "     B-MISC      0.820     0.777     0.798       694\n",
      "     I-MISC      0.584     0.704     0.638       213\n",
      "      B-ORG      0.803     0.730     0.765      1660\n",
      "      I-ORG      0.695     0.766     0.729       834\n",
      "      B-PER      0.868     0.848     0.858      1608\n",
      "      I-PER      0.908     0.944     0.926      1154\n",
      "\n",
      "avg / total      0.827     0.821     0.823      8076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_score = cross_val_score(crf, X_val, y_val, cv=5, scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82146043 0.69796028 0.8176525  0.81892228 0.69484772]\n",
      "0.7701686404202621\n"
     ]
    }
   ],
   "source": [
    "print(x_val_score)\n",
    "print(x_val_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 21.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 53s, sys: 15.7 s, total: 4min 9s\n",
      "Wall time: 21min 59s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# params_space = {\n",
    "#     'c1': scipy.stats.expon(scale=0.5),\n",
    "#     'c2': scipy.stats.expon(scale=0.05),\n",
    "# }\n",
    "\n",
    "# rs_train = RandomizedSearchCV(crf, params_space,\n",
    "#                         cv=3,\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1,\n",
    "#                         n_iter=50,\n",
    "#                         scoring=f1_scorer)\n",
    "# rs_train.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 50 candidates, totalling 150 fits  \n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.7min  \n",
    "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 21.5min finished  \n",
    "CPU times: user 3min 53s, sys: 15.7 s, total: 4min 9s  \n",
    "Wall time: 21min 59s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_train_best_params_ = {'c1': 0.001262621084804322, 'c2': 0.07748342053200617}\n",
    "rs_train_best_score_ = 0.856466684355955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'c1': 0.001262621084804322, 'c2': 0.07748342053200617}\n",
      "Best CV score: 0.856466684355955\n"
     ]
    }
   ],
   "source": [
    "print('Best params:', rs_train_best_params_)\n",
    "print('Best CV score:', rs_train_best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 844 ms, total: 1min 3s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# params_space = {\n",
    "#     'c1': scipy.stats.expon(scale=0.5),\n",
    "#     'c2': scipy.stats.expon(scale=0.05),\n",
    "# }\n",
    "\n",
    "# rs_val = RandomizedSearchCV(crf, params_space,\n",
    "#                         cv=3,\n",
    "#                         verbose=1,\n",
    "#                         n_jobs=-1,\n",
    "#                         n_iter=50,\n",
    "#                         scoring=f1_scorer)\n",
    "# rs_val.fit(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting 3 folds for each of 50 candidates, totalling 150 fits  \n",
    "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.0min  \n",
    "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  5.5min finished  \n",
    "CPU times: user 1min 2s, sys: 844 ms, total: 1min 3s  \n",
    "Wall time: 5min 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_val_best_params_ = {'c1': 0.097424410654595, 'c2': 0.02559303567607237}\n",
    "rs_val_best_score_ = 0.7813431798834048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'c1': 0.097424410654595, 'c2': 0.02559303567607237}\n",
      "Best CV score: 0.7813431798834048\n"
     ]
    }
   ],
   "source": [
    "print('Best params:', rs_val_best_params_)\n",
    "print('Best CV score:', rs_val_best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Classifier Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 s, sys: 134 ms, total: 32.1 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=rs_train_best_params_['c1'],\n",
    "    c2=rs_train_best_params_['c2'],\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276477008704834"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.866     0.880     0.873      1658\n",
      "      I-LOC      0.798     0.729     0.762       255\n",
      "     B-MISC      0.816     0.772     0.793       694\n",
      "     I-MISC      0.561     0.690     0.619       213\n",
      "      B-ORG      0.814     0.732     0.771      1660\n",
      "      I-ORG      0.695     0.775     0.732       834\n",
      "      B-PER      0.879     0.855     0.867      1608\n",
      "      I-PER      0.913     0.952     0.932      1154\n",
      "\n",
      "avg / total      0.832     0.825     0.828      8076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validation RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.4 s, sys: 83.1 ms, total: 31.5 s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=rs_val_best_params_['c1'],\n",
    "    c2=rs_val_best_params_['c2'],\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8204993488141177"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.864     0.869     0.866      1658\n",
      "      I-LOC      0.760     0.745     0.752       255\n",
      "     B-MISC      0.798     0.784     0.791       694\n",
      "     I-MISC      0.561     0.690     0.619       213\n",
      "      B-ORG      0.813     0.717     0.762      1660\n",
      "      I-ORG      0.706     0.748     0.726       834\n",
      "      B-PER      0.858     0.860     0.859      1608\n",
      "      I-PER      0.893     0.956     0.923      1154\n",
      "\n",
      "avg / total      0.823     0.820     0.820      8076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
