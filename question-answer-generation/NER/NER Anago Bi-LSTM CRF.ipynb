{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import anago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('datasets/conll2003/train.txt', 'r')\n",
    "lines = f.readlines()\n",
    "\n",
    "del lines[0]\n",
    "del lines[0]\n",
    "\n",
    "corpus_token = []\n",
    "corpus_tag = []\n",
    "token_list = []\n",
    "tag_list = []\n",
    "for line in lines:\n",
    "    splitter = line.strip().split(' ')\n",
    "    if splitter[0] == '-DOCSTART-':\n",
    "        corpus_token.append(token_list)\n",
    "        corpus_tag.append(tag_list)\n",
    "        token_list = []\n",
    "        tag_list = []\n",
    "    elif splitter[0] == '':\n",
    "        continue\n",
    "    else:\n",
    "        token_list.append(splitter[0])\n",
    "        tag_list.append(splitter[3])\n",
    "        \n",
    "f = open('datasets/conll2003/test.txt', 'r')\n",
    "lines = f.readlines()\n",
    "\n",
    "del lines[0]\n",
    "del lines[0]\n",
    "\n",
    "test_token = []\n",
    "test_tag = []\n",
    "token_list = []\n",
    "tag_list = []\n",
    "for line in lines:\n",
    "    splitter = line.strip().split(' ')\n",
    "    if splitter[0] == '-DOCSTART-':\n",
    "        test_token.append(token_list)\n",
    "        test_tag.append(tag_list)\n",
    "        token_list = []\n",
    "        tag_list = []\n",
    "    elif splitter[0] == '':\n",
    "        continue\n",
    "    else:\n",
    "        token_list.append(splitter[0])\n",
    "        tag_list.append(splitter[3])\n",
    "\n",
    "        \n",
    "f = open('datasets/conll2003/valid.txt', 'r')\n",
    "lines = f.readlines()\n",
    "\n",
    "del lines[0]\n",
    "del lines[0]\n",
    "\n",
    "val_token = []\n",
    "val_tag = []\n",
    "token_list = []\n",
    "tag_list = []\n",
    "for line in lines:\n",
    "    splitter = line.strip().split(' ')\n",
    "    if splitter[0] == '-DOCSTART-':\n",
    "        val_token.append(token_list)\n",
    "        val_tag.append(tag_list)\n",
    "        token_list = []\n",
    "        tag_list = []\n",
    "    elif splitter[0] == '':\n",
    "        continue\n",
    "    else:\n",
    "        token_list.append(splitter[0])\n",
    "        tag_list.append(splitter[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 108s 3s/step - loss: 10.6730\n",
      " - f1: 0.00\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.00      0.00      0.00       921\n",
      "        PER       0.00      0.00      0.00      1840\n",
      "        LOC       0.00      0.00      0.00      1835\n",
      "        ORG       0.00      0.00      0.00      1333\n",
      "\n",
      "avg / total       0.00      0.00      0.00      5929\n",
      "\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 90s 2s/step - loss: 10.3707\n",
      " - f1: 0.17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.00      0.00      0.00       921\n",
      "        PER       0.00      0.00      0.00      1840\n",
      "        LOC       0.16      0.00      0.01      1835\n",
      "        ORG       0.00      0.00      0.00      1333\n",
      "\n",
      "avg / total       0.05      0.00      0.00      5929\n",
      "\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 81s 2s/step - loss: 10.1713\n",
      " - f1: 34.37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.42      0.01      0.02       921\n",
      "        PER       0.54      0.30      0.39      1840\n",
      "        LOC       0.33      0.71      0.45      1835\n",
      "        ORG       0.19      0.01      0.02      1333\n",
      "\n",
      "avg / total       0.38      0.32      0.27      5929\n",
      "\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 10.0071\n",
      " - f1: 51.39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.00      0.00      0.00       921\n",
      "        PER       0.71      0.56      0.63      1840\n",
      "        LOC       0.49      0.71      0.58      1835\n",
      "        ORG       0.40      0.48      0.44      1333\n",
      "\n",
      "avg / total       0.46      0.50      0.47      5929\n",
      "\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 9.9089\n",
      " - f1: 59.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.85      0.21      0.34       921\n",
      "        PER       0.74      0.56      0.64      1840\n",
      "        LOC       0.70      0.72      0.71      1835\n",
      "        ORG       0.44      0.65      0.52      1333\n",
      "\n",
      "avg / total       0.68      0.58      0.59      5929\n",
      "\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 9.8336\n",
      " - f1: 71.88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.73      0.49      0.59       921\n",
      "        PER       0.75      0.82      0.79      1840\n",
      "        LOC       0.81      0.76      0.78      1835\n",
      "        ORG       0.59      0.65      0.62      1333\n",
      "\n",
      "avg / total       0.73      0.71      0.72      5929\n",
      "\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 84s 2s/step - loss: 9.7908\n",
      " - f1: 76.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.62      0.68      0.65       921\n",
      "        PER       0.84      0.84      0.84      1840\n",
      "        LOC       0.82      0.81      0.81      1835\n",
      "        ORG       0.69      0.65      0.67      1333\n",
      "\n",
      "avg / total       0.77      0.76      0.76      5929\n",
      "\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 81s 2s/step - loss: 9.7597\n",
      " - f1: 78.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.71      0.71      0.71       921\n",
      "        PER       0.81      0.90      0.85      1840\n",
      "        LOC       0.83      0.84      0.83      1835\n",
      "        ORG       0.73      0.65      0.69      1333\n",
      "\n",
      "avg / total       0.78      0.79      0.79      5929\n",
      "\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 9.7389\n",
      " - f1: 79.77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.78      0.69      0.74       921\n",
      "        PER       0.86      0.83      0.84      1840\n",
      "        LOC       0.85      0.84      0.85      1835\n",
      "        ORG       0.68      0.75      0.72      1333\n",
      "\n",
      "avg / total       0.81      0.79      0.80      5929\n",
      "\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 85s 2s/step - loss: 9.7264\n",
      " - f1: 81.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.79      0.71      0.75       921\n",
      "        PER       0.83      0.89      0.86      1840\n",
      "        LOC       0.87      0.85      0.86      1835\n",
      "        ORG       0.76      0.74      0.75      1333\n",
      "\n",
      "avg / total       0.82      0.82      0.82      5929\n",
      "\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 9.7170\n",
      " - f1: 81.57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.72      0.74      0.73       921\n",
      "        PER       0.87      0.85      0.86      1840\n",
      "        LOC       0.88      0.85      0.86      1835\n",
      "        ORG       0.74      0.77      0.75      1333\n",
      "\n",
      "avg / total       0.82      0.81      0.82      5929\n",
      "\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 83s 2s/step - loss: 9.7088\n",
      " - f1: 82.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.78      0.74      0.76       921\n",
      "        PER       0.86      0.86      0.86      1840\n",
      "        LOC       0.90      0.85      0.87      1835\n",
      "        ORG       0.76      0.77      0.76      1333\n",
      "\n",
      "avg / total       0.84      0.82      0.83      5929\n",
      "\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 82s 2s/step - loss: 9.7039\n",
      " - f1: 82.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.76      0.75      0.76       921\n",
      "        PER       0.86      0.86      0.86      1840\n",
      "        LOC       0.89      0.85      0.87      1835\n",
      "        ORG       0.78      0.75      0.76      1333\n",
      "\n",
      "avg / total       0.84      0.82      0.83      5929\n",
      "\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 82s 2s/step - loss: 9.6994\n",
      " - f1: 82.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.76      0.75      0.76       921\n",
      "        PER       0.86      0.88      0.87      1840\n",
      "        LOC       0.89      0.86      0.88      1835\n",
      "        ORG       0.76      0.77      0.77      1333\n",
      "\n",
      "avg / total       0.83      0.83      0.83      5929\n",
      "\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 82s 2s/step - loss: 9.6962\n",
      " - f1: 83.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       MISC       0.77      0.75      0.76       921\n",
      "        PER       0.89      0.84      0.87      1840\n",
      "        LOC       0.89      0.86      0.87      1835\n",
      "        ORG       0.77      0.77      0.77      1333\n",
      "\n",
      "avg / total       0.85      0.82      0.83      5929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = anago.Sequence()\n",
    "model.fit(corpus_token, corpus_tag, val_token, val_tag, epochs=15, batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601975489299433"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_token, test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
