{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer, pos_tag, sent_tokenize, word_tokenize\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('dataset/SQuAD/train-v2.0.json') as f:\n",
    "    json_data = json.load(f)['data']\n",
    "\n",
    "    for i in range(len(json_data)):\n",
    "        json_data_i = json_data[i]['paragraphs']\n",
    "        \n",
    "        for j in range(1):\n",
    "            paragraph = json_data_i[j]['context']\n",
    "            \n",
    "            data.append([sentence for sentence in sent_tokenize(paragraph)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence importance sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 John was born to Henry II of England and Eleanor of Aquitaine on 24 December 1166.\n",
      "1 Henry had inherited significant territories along the Atlantic seaboard—Anjou, Normandy and England—and expanded his empire by conquering Brittany.\n",
      "2 Henry married the powerful Eleanor of Aquitaine, who reigned over the Duchy of Aquitaine and had a tenuous claim to Toulouse and Auvergne in southern France, in addition to being the former wife of Louis VII of France.\n",
      "3 The result was the Angevin Empire, named after Henry's paternal title as Count of Anjou and, more specifically, its seat in Angers.\n",
      "4 [nb 2] The Empire, however, was inherently fragile: although all the lands owed allegiance to Henry, the disparate parts each had their own histories, traditions and governance structures.\n",
      "5 As one moved south through Anjou and Aquitaine, the extent of Henry's power in the provinces diminished considerably, scarcely resembling the modern concept of an empire at all.\n",
      "6 Some of the traditional ties between parts of the empire such as Normandy and England were slowly dissolving over time.\n",
      "7 It was unclear what would happen to the empire on Henry's death.\n",
      "8 Although the custom of primogeniture, under which an eldest son would inherit all his father's lands, was slowly becoming more widespread across Europe, it was less popular amongst the Norman kings of England.\n",
      "9 Most believed that Henry would divide the empire, giving each son a substantial portion, and hoping that his children would continue to work together as allies after his death.\n",
      "10 To complicate matters, much of the Angevin empire was held by Henry only as a vassal of the King of France of the rival line of the House of Capet.\n",
      "11 Henry had often allied himself with the Holy Roman Emperor against France, making the feudal relationship even more challenging.\n"
     ]
    }
   ],
   "source": [
    "idx = 143\n",
    "\n",
    "for i in range(len(data[idx])):\n",
    "    print(i, data[idx][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 6]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_selection import MultiWordPhraseExtractor, preprocess\n",
    "\n",
    "rank = MultiWordPhraseExtractor(window_size=5, top_keywords=7).summarize(preprocess(' '.join(data[idx])), top=3)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model Success\n",
      "****************************************************************************************************\n",
      "default values:\n",
      "senna path:\n",
      " D:\\Programming\\question-answer-generation\\QuestionGeneration\\lib\\senna\\ \n",
      "Dependencie parser:\n",
      " D:\\Programming\\question-answer-generation\\QuestionGeneration\\lib\\\n",
      "Stanford parser clr java -cp stanford-parser.jar edu.stanford.nlp.trees.EnglishGrammaticalStructure -treeFile in.parse -collapsed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from question_generation import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The building was on fire, and it wasn't my fault.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence = Sentence(data[idx][0])\n",
    "sentence = Sentence(\"The building was on fire, and it wasn't my fault.\")\n",
    "sentence.sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (S\n",
      "    (NP (DT The) (NN building))\n",
      "    (VP (VBD was) (PP (IN on) (NP (NN fire)))))\n",
      "  (, ,)\n",
      "  (CC and)\n",
      "  (S (NP (PRP it)) (VP (VBD was) (RB n't) (NP (PRP$ my) (NN fault))))\n",
      "  (. .))\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "sentence.parse_constituents()\n",
    "print(list(map(lambda x: print(x), sentence.constituent_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('building', 'O'),\n",
       " ('was', 'O'),\n",
       " ('on', 'O'),\n",
       " ('fire', 'O'),\n",
       " ('and', 'O'),\n",
       " ('it', 'O'),\n",
       " ('wasn', 'O'),\n",
       " ('t', 'O'),\n",
       " ('my', 'O'),\n",
       " ('fault', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.extract_named_entities()\n",
    "sentence.ner_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence.parse_srl()\n",
    "# for clause in sentence.srl:\n",
    "#     print(clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_generation import GapSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (S\n",
      "  (NP (DT The) (NN building))\n",
      "  (VP (VBD was) (PP (IN on) (NP (NN fire)))))\n",
      "1 (S\n",
      "  (NP (DT The) (NN building))\n",
      "  (VP (VBD was) (PP (IN on) (NP (NN fire)))))\n",
      "2 (S (NP (PRP it)) (VP (VBD was) (RB n't) (NP (PRP$ my) (NN fault))))\n",
      "3 (S (NP (PRP it)) (VP (VBD was) (RB n't) (NP (PRP$ my) (NN fault))))\n"
     ]
    }
   ],
   "source": [
    "gapper = GapSelector(sentence)\n",
    "\n",
    "candidates = gapper.process()\n",
    "for i, parent in enumerate(gapper.parents):\n",
    "    print(i, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The building was on fire, and it wasn't my fault.\n",
      "\n",
      "Q: _____ was on fire\n",
      "A: The building\n",
      "\n",
      "Q: The building was on _____\n",
      "A: fire\n",
      "\n",
      "Q: _____ wasn't my fault\n",
      "A: it\n",
      "\n",
      "Q: it wasn't _____\n",
      "A: my fault\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentence: {}\\n\".format(sentence.sentence))\n",
    "for candidate in candidates:\n",
    "    print(\"Q: {}\\nA: {}\\n\".format(candidate['question'], candidate['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS\n",
      "Q: What was on fire?\n",
      "A: The building\n",
      "\n",
      "PP\n",
      "Q: The building The building?\n",
      "A: fire\n",
      "\n",
      "SS\n",
      "Q: What wasn't my fault?\n",
      "A: it\n",
      "\n",
      "OO\n",
      "NOT\n",
      "Q: \n",
      "A: my fault\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simple_nlg import SimpleNLG\n",
    "\n",
    "for candidate in gapper.candidates:\n",
    "    nlg = SimpleNLG(sentence, candidate)\n",
    "    question = nlg.convert_to_question()\n",
    "    \n",
    "    print(\"Q: {}\\nA: {}\\n\".format(question, candidate['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_in_dict(answer, ne_dict, key):\n",
    "#     if key not in ne_dict:\n",
    "#         return False\n",
    "#     if answer in ne_dict[key]:\n",
    "#         return True\n",
    "    \n",
    "#     for word in answer.split(' '):\n",
    "#         if word in ne_dict[key]:\n",
    "#             return True\n",
    "#     return False    \n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# from simple_nlg import init_simple_nlg\n",
    "\n",
    "# gateway = init_simple_nlg()\n",
    "# lexicon = gateway.jvm.Lexicon.getDefaultLexicon()\n",
    "# nlg_factory = gateway.jvm.NLGFactory(lexicon)\n",
    "# realiser = gateway.jvm.Realiser(lexicon)\n",
    "\n",
    "# wnl = WordNetLemmatizer()\n",
    "\n",
    "# blank = '_____'\n",
    "\n",
    "# for candidate in gapper.candidates:\n",
    "#     entity = candidate['entity']\n",
    "#     parent = candidate['parent']\n",
    "#     answer = candidate['answer']\n",
    "#     question = candidate['question']\n",
    "    \n",
    "#     # Subject\n",
    "#     if entity.parent().label() == 'S':\n",
    "#         if 'PER' in sentence.named_entities_dict and answer in sentence.named_entities_dict['PER']:\n",
    "#             question = question.replace(blank, \"who\")\n",
    "#         else:\n",
    "#             question = question.replace(blank, \"what\")\n",
    "        \n",
    "#         q = list(question)\n",
    "#         q[0] = q[0].upper()\n",
    "#         if q[-1] == '.':\n",
    "#             q[-1] = '?'\n",
    "#         else:\n",
    "#             q.append('?')\n",
    "#         question = ''.join(q)\n",
    "        \n",
    "#     # Object\n",
    "#     elif entity.parent().parent().label() == 'S':\n",
    "#         p = nlg_factory.createClause()\n",
    "#         p.setObject(answer)\n",
    "        \n",
    "#         for child in parent:\n",
    "#             # Subject\n",
    "#             if child.label() == 'NP':\n",
    "#                 p.setSubject(' '.join(child.leaves()))\n",
    "            \n",
    "#             # Verb\n",
    "#             elif child.label() == 'VP':\n",
    "#                 for gchild in child:\n",
    "#                     if gchild.label() in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "#                         p.setVerb(wnl.lemmatize(gchild.leaves()[0], pos='v'))\n",
    "#                         if gchild.label() in ['VB', 'VBG', 'VBP', 'VBZ']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.TENSE, gateway.jvm.Tense.PRESENT)\n",
    "#                         elif gchild.label() in ['VBD', 'VBN']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.TENSE, gateway.jvm.Tense.PAST)\n",
    "#                     elif gchild.label() == 'RB':\n",
    "#                         if gchild.leaves()[0] in ['n\\'t', 'not']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.NEGATED, True)\n",
    "                        \n",
    "#             elif child.label() == 'PP':\n",
    "#                 p.addComplement(' '.join(child.leaves()))\n",
    "                        \n",
    "#         if 'PER' in sentence.named_entities_dict and answer in sentence.named_entities_dict['PER']:\n",
    "#             p.setFeature(gateway.jvm.Feature.INTERROGATIVE_TYPE, gateway.jvm.InterrogativeType.WHO_OBJECT)\n",
    "#         else:\n",
    "#             p.setFeature(gateway.jvm.Feature.INTERROGATIVE_TYPE, gateway.jvm.InterrogativeType.WHAT_OBJECT)\n",
    "            \n",
    "#         question = realiser.realiseSentence(p)\n",
    "        \n",
    "#     elif entity.parent().label() == 'PP':\n",
    "#         p = nlg_factory.createClause()\n",
    "        \n",
    "#         for child in parent:\n",
    "#             # Subject\n",
    "#             if child.label() == 'NP':\n",
    "#                 p.setSubject(' '.join(child.leaves()))\n",
    "            \n",
    "#             # Verb\n",
    "#             elif child.label() == 'VP':\n",
    "#                 for gchild in child:\n",
    "#                     if gchild.label() in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "#                         p.setVerb(wnl.lemmatize(gchild.leaves()[0], pos='v'))\n",
    "#                         if gchild.label() in ['VB', 'VBG', 'VBP', 'VBZ']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.TENSE, gateway.jvm.Tense.PRESENT)\n",
    "#                         elif gchild.label() in ['VBD', 'VBN']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.TENSE, gateway.jvm.Tense.PAST)\n",
    "#                     elif gchild.label() == 'NP':\n",
    "#                         p.setObject(' '.join(gchild.leaves()))\n",
    "#                     elif gchild.label() == 'RB':\n",
    "#                         if gchild.leaves()[0] in ['n\\'t', 'not']:\n",
    "#                             p.setFeature(gateway.jvm.Feature.NEGATED, True)                        \n",
    "#             elif child.label() == 'PP':\n",
    "#                 p.addComplement(' '.join(child.leaves()))\n",
    "                \n",
    "#         p.setFeature(gateway.jvm.Feature.INTERROGATIVE_TYPE, gateway.jvm.InterrogativeType.WHO_INDIRECT_OBJECT)\n",
    "#         question = realiser.realiseSentence(p)\\\n",
    "#             .replace(answer, '')\\\n",
    "#             .replace('  ', ' ')\\\n",
    "#             .replace('to?', '?')\\\n",
    "#             .replace(' ?', '?')\n",
    "#         question = re.sub(r\"-LRB- (.*) -RRB-\", r\"(\\1)\", question)\n",
    "        \n",
    "#         if check_in_dict(answer, sentence.named_entities_dict, 'PER'):\n",
    "#             pass\n",
    "#         elif check_in_dict(answer, sentence.named_entities_dict, 'LOC'):\n",
    "#             question = question.replace('Who', 'Where')\n",
    "#         else:\n",
    "#             question = question.replace('Who', 'What')\n",
    "            \n",
    "#     print(\"Q: {}\\nA: {}\\n\".format(question, candidate['answer']))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
